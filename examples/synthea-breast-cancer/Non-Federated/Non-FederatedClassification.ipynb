{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "565b1efc",
   "metadata": {},
   "source": [
    "# Non-Federated Logistic Regression on the Synthea MCODE Breast Cancer Dataset\n",
    "This notebook gives a simple logistic regression classification task over the described Synthea dataset. The notebook assumes that you have followed the instructions in the example's README.md. This should involve setting up the rego_development_playground, Katsu GraphQL interface, and ingesting the synthea MCODE dataset locally.\n",
    "\n",
    "## Fetching the Data from our GraphQL Server\n",
    "We first fetch the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaa0efe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "query = \"\"\"\n",
    "query{\n",
    "  katsuDataModels\n",
    "  {\n",
    "    mcodeDataModels\n",
    "    {\n",
    "      mcodePackets{\n",
    "        subject {\n",
    "          dateOfBirth\n",
    "          sex\n",
    "        }\n",
    "        cancerCondition {\n",
    "          dateOfDiagnosis\n",
    "        }\n",
    "        cancerRelatedProcedures {\n",
    "          code {\n",
    "            label\n",
    "          }\n",
    "        }\n",
    "        cancerDiseaseStatus {\n",
    "          label\n",
    "        }\n",
    "        medicationStatement {\n",
    "          medicationCode {\n",
    "            label\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "url = \"http://localhost:7999/graphql\"\n",
    "req = requests.post(url, json={'query': query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ede8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(req.status_code)\n",
    "all_results = json.loads(req.text)['data']['katsuDataModels']['mcodeDataModels']['mcodePackets'] # what we care about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d77a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_results)) # this number should read ~1884 assuming you have ingested the entire synthea dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0234d",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Here we drop empty columns, adjust null values, or cut rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a77317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.json_normalize(all_results) # converts our JSON list into a normalized pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670bc09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df:\n",
    "    if df[col].astype(str).nunique() == 1:\n",
    "        print(col)\n",
    "        print(df[col].astype(str).unique()) # we drop null-valued and single-valued columns.\n",
    "        df = df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65414dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04f4247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['cancerDiseaseStatus.label']) # drop any rows that have empty disease status labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e32a8",
   "metadata": {},
   "source": [
    "### Enumerate Cancer_Related_Procedures into Independent Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1991c88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_procs = set()\n",
    "for _, row in df.iterrows():\n",
    "    for i in row['cancerRelatedProcedures']:\n",
    "        all_procs.add(i['code']['label'])\n",
    "        \n",
    "dict_list_procs = []\n",
    "for _, row in df.iterrows():\n",
    "    row_dict = dict.fromkeys(all_procs, 0)\n",
    "    for i in row['cancerRelatedProcedures']:\n",
    "        row_dict[i['code']['label']] += 1\n",
    "    dict_list_procs.append(row_dict)\n",
    "df_procs = pd.DataFrame(dict_list_procs)\n",
    "df_procs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d9b4ea",
   "metadata": {},
   "source": [
    "### Enumerate Medication_Statement into Independent Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c396d09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_meds = set()\n",
    "for _, row in df.iterrows():\n",
    "    for i in row['medicationStatement']:\n",
    "        all_meds.add(i['medicationCode']['label'])\n",
    "        \n",
    "dict_list_meds = []\n",
    "for _, row in df.iterrows():\n",
    "    row_dict = dict.fromkeys(all_meds, 0)\n",
    "    for i in row['medicationStatement']:\n",
    "        row_dict[i['medicationCode']['label']] += 1\n",
    "    dict_list_meds.append(row_dict)\n",
    "df_meds = pd.DataFrame(dict_list_meds)\n",
    "df_meds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf06ac",
   "metadata": {},
   "source": [
    "### Parse Diagnosis Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b408aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def parse_diagnosis_age(row) -> float:\n",
    "    \"\"\"\n",
    "    A function that returns the difference (in hours) between the diagnosis date and born date of a dataframe entry.\n",
    "    \n",
    "    Input: A (Katsu returned) JSON object of the MCODE data.\n",
    "    Output: The difference between the diagnosis date and born date.\n",
    "    \"\"\"\n",
    "    diag_date = row['cancerCondition'][0]['dateOfDiagnosis']\n",
    "    diag_age = datetime.datetime(int(diag_date[0:4]), int(diag_date[5:7]), int(diag_date[8:10]))\n",
    "    born_date = row['subject.dateOfBirth']\n",
    "    born_age = datetime.datetime(int(born_date[0:4]), int(born_date[5:7]), int(born_date[8:10]))\n",
    "    difference = diag_age - born_age\n",
    "    diff_in_hrs = divmod(difference.total_seconds(), 3600)[0] # rounded down\n",
    "    return diff_in_hrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_age = df.apply(lambda row: parse_diagnosis_age(row), axis=1)\n",
    "diag_age_rename = diag_age.rename(\"diagnosisAge\")\n",
    "df = df.join(pd.DataFrame(diag_age_rename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855e3cb",
   "metadata": {},
   "source": [
    "### Drop Cancer Condition\n",
    "This probably wouldn't be done in a real workflow with the Synthea MCODE dataset, but I personally cannot parse what, if any of this, is relevant, so I just decided to drop the column since they all have breast cancer.\n",
    "\n",
    "I also drop the medication_statement and cancer_related_procedures since we've parsed information from them already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee8700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(axis=1, labels=['cancerCondition', 'medicationStatement', 'cancerRelatedProcedures'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337aaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = pd.concat([df.reset_index(), pd.DataFrame(dict_list_procs), pd.DataFrame(dict_list_meds)], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a403bd",
   "metadata": {},
   "source": [
    "### One Hot Encode Cancer_Disease_Status.Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dbeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(dfnew['cancerDiseaseStatus.label'])\n",
    "dfnew = dfnew.drop('cancerDiseaseStatus.label', axis=1)\n",
    "dfnew = dfnew.join(one_hot[\"Patient's condition improved\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880fbcc6",
   "metadata": {},
   "source": [
    "### Drop Extraneous Columns\n",
    "We drop any columns that deliver meta-information or information that is already provided by other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e82a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfnew = dfnew.drop(['subject.dateOfBirth', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bc96da",
   "metadata": {},
   "source": [
    "## Undersampling the Majority Class\n",
    "As is pretty clear, we have 1381 data points where the patient's condition improves, with only 61 where they don't. While this is great for the patient, this is not well-balanced data for training a naive binary classifier. Conventional accuracy metrics will not suffice in providing a good understanding of whether the classifier is actually effective, and conventional classifiers will naively optimize for accuracy. Thus, we attempt to balance the dataset by massively reducing the number of data points in our training data. \n",
    "\n",
    "By randomly sampling 61 of these 1381 data points, we balance the distribution of data points among each class. We then train a number of classical ML algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb57a22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_entries = dfnew[dfnew[\"Patient's condition improved\"] == 1]\n",
    "positive_sample = positive_entries.sample(n=61, random_state=1729)\n",
    "positive_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0a4fdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "negative_entries = dfnew[dfnew[\"Patient's condition improved\"] == 0]\n",
    "negative_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_sample = positive_sample.append(negative_entries)\n",
    "X = ml_sample.drop(\"Patient's condition improved\", axis=1)\n",
    "y = ml_sample[\"Patient's condition improved\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4a673c",
   "metadata": {},
   "source": [
    "Since we don't have many points to train with, we don't split into validation sets as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb5dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1729)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db4af6",
   "metadata": {},
   "source": [
    "## Creating a Model Pipeline\n",
    "Since we have many dimensions relative to our training data volume, we use principal component analysis (PCA) to reduce the number of dimensions in our training data. This will also be used when evaluating test points, and so is part of our model as the first technique in the model 'pipeline'. \n",
    "\n",
    "We greatly. reduce the number of dimensions by enforcing that our PCA must finish with 10 dimensions from our dataframe's original 37. Also, we employ the use of PCA whitening to maintain non-correlation between our post-PCA input dimensions.\n",
    "\n",
    "For our logistic regression, we allow the optimizer to iterate 10000 times to converge. We set a low tolerance (default is 1 for a logistic regression) to ensure strict stopping criteria close to a minimum, at the cost of training speed. We set the solver to 'liblinear' since scikit-learn says that it's suitable for low-volume training data. Since we have little training data, we also set C (the regularization term) to a very low number. This *increases* the regularization parameter's influence, which minimizes overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a55921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "pca = PCA(n_components=10, whiten=True)\n",
    "logistic = LogisticRegression(max_iter=10000, tol=0.01, solver='liblinear', random_state=1729, C=0.1, verbose=1)\n",
    "pipe = Pipeline(steps=[(\"pca\", pca), (\"logistic\", logistic)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b303b45",
   "metadata": {},
   "source": [
    "Finally, we train our model on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288d0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e879df",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "Since our sample has been artificially balanced such that positive and negative labels exist in a 1:1 ratio, accuracy is a genuinely good metric for predicting effectiveness. Then, evaluating our model is as simple as calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ced53",
   "metadata": {},
   "source": [
    "We also evaluate on the AUC score of our model, which is the area under a ROC curve. A value of 0.5 is equivalent to a coin toss. Values closer to 1 are better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = pipe.predict(X_test)\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34637540",
   "metadata": {},
   "source": [
    "Unfortunately this is still poor discrimination by our classifier; far better than a coin toss, but still not great. Provided more *well-distributed* data, this number could certainly see substantial increases. Hyperparameter searching could also provide benefit, but at such little data this was not tested."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
